{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89ba841-410f-4b9e-8e8a-df41c96be9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0851f8c-dbac-454c-b1f2-62395bed2a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egg clap (1377, 100)\n",
      "egg clap (1357, 20, 100)\n",
      "wrist clap (1430, 100)\n",
      "wrist clap (1410, 20, 100)\n",
      "fist clap (1405, 100)\n",
      "fist clap (1385, 20, 100)\n",
      "edge clap (1432, 100)\n",
      "edge clap (1412, 20, 100)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time, os, sys\n",
    "\n",
    "actions = ['egg clap', 'wrist clap', 'fist clap', 'edge clap']\n",
    "seq_length = 20 # 웹 크기\n",
    "secs_for_action = 30 # 데이터 수집 시간 (초)\n",
    "\n",
    "# MediaPipe hands model\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.3,\n",
    "    min_tracking_confidence=0.3)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "while cap.isOpened():\n",
    "    for idx, action in enumerate(actions):\n",
    "        if(idx == 4): break\n",
    "        data = []\n",
    "\n",
    "        ret, img = cap.read()\n",
    "\n",
    "        img = cv2.flip(img, 1)\n",
    "\n",
    "        cv2.putText(img, f'Waiting for collecting {action.upper()} action...', org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(3000)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        while time.time() - start_time < secs_for_action:\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            img = cv2.flip(img, 1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if result.multi_hand_landmarks is not None:\n",
    "                for res in result.multi_hand_landmarks:\n",
    "                    joint = np.zeros((21, 4))\n",
    "                    for j, lm in enumerate(res.landmark):\n",
    "                        joint[j] = [lm.x, lm.y, lm.z, lm.visibility] # visibility는 손가락이 보이는지 안 보이는지 확인\n",
    "\n",
    "                    # Compute angles between joints\n",
    "                    v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "                    v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "                    v = v2 - v1 # [20, 3]\n",
    "                    # Normalize v\n",
    "                    v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "                    # Get angle using arcos of dot product\n",
    "                    angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                        v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                        v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "                    angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "                    angle_label = np.array([angle], dtype=np.float32)\n",
    "                    angle_label = np.append(angle_label, idx)\n",
    "\n",
    "                    d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "                    data.append(d)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            cv2.imshow('img', img)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        data = np.array(data)\n",
    "        print(action, data.shape)\n",
    "        np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "        # Create sequence data\n",
    "        full_seq_data = []\n",
    "        for seq in range(len(data) - seq_length):\n",
    "            full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "        full_seq_data = np.array(full_seq_data)\n",
    "        print(action, full_seq_data.shape)\n",
    "        np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "\n",
    "    time.sleep(10)  # 파일 크기가 커질 경우 time.sleep 기간을 더 크게 설정 (현재는 30s)\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405cbce2-3061-4cff-bb19-bb2be3d3176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# TensorFlow가 실행될 때 이를 참조하여 GPU 사용 및 메모리 할당을 제어\n",
    "# 메모리 최적화를 위해 사용\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' \n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a47e968-2608-47ac-a82d-c4edb3c4232a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5564, 20, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'egg clap',\n",
    "    'wrist clap',\n",
    "    'fist clap',\n",
    "    'edge clap'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('seq_edge clap_1714908984.npy'),\n",
    "    np.load('seq_egg clap_1714908984.npy'),\n",
    "    np.load('seq_fist clap_1714908984.npy'),\n",
    "    np.load('seq_wrist clap_1714908984.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca72a6d5-4e81-4232-9b36-cf39298fc19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5564, 20, 99)\n",
      "(5564,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f27958d4-fa46-47fd-a3f9-479e58313e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5564, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# 원핫인코딩 실행\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50defd59-c3ff-4499-b31d-2806e9e8d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5007, 20, 99) (5007, 4)\n",
      "(557, 20, 99) (557, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "# 10%를 test_set\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7df0db-cac0-460b-aaa1-7710b2a9294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                41984     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44196 (172.64 KB)\n",
      "Trainable params: 44196 (172.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93de11b2-a477-463e-ae28-e19cd4cfe1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:From c:\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "155/157 [============================>.] - ETA: 0s - loss: 3.0974 - acc: 0.8823\n",
      "Epoch 1: val_acc improved from -inf to 1.00000, saving model to models\\model2.keras\n",
      "157/157 [==============================] - 3s 8ms/step - loss: 3.0683 - acc: 0.8834 - val_loss: 1.1358e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 6.4025e-05 - acc: 1.0000\n",
      "Epoch 2: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 6.3863e-05 - acc: 1.0000 - val_loss: 3.5479e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 2.4115e-05 - acc: 1.0000\n",
      "Epoch 3: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.4115e-05 - acc: 1.0000 - val_loss: 1.4758e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 1.1273e-05 - acc: 1.0000\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.1029e-05 - acc: 1.0000 - val_loss: 7.6198e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 6.0037e-06 - acc: 1.0000\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 6.0037e-06 - acc: 1.0000 - val_loss: 4.7912e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 3.4812e-06 - acc: 1.0000\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 3.4420e-06 - acc: 1.0000 - val_loss: 3.0361e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 1.9182 - acc: 0.8796\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.9403 - acc: 0.8794 - val_loss: 13.3612 - val_acc: 0.7415 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "149/157 [===========================>..] - ETA: 0s - loss: 14.9778 - acc: 0.5510\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.2785 - acc: 0.5666 - val_loss: 0.0983 - val_acc: 0.9569 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 0.1171 - acc: 0.9843\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1134 - acc: 0.9848 - val_loss: 0.0081 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9992\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0083 - acc: 0.9992 - val_loss: 0.0046 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 0.0052 - acc: 0.9998\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.0037 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9998\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0039 - acc: 0.9998 - val_loss: 0.0026 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "150/157 [===========================>..] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.5204e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 9.6707e-04 - acc: 1.0000\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 9.6692e-04 - acc: 1.0000 - val_loss: 5.3689e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 8.6326e-04 - acc: 1.0000\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 8.6108e-04 - acc: 1.0000 - val_loss: 6.4793e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 7.8771e-04 - acc: 1.0000\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 7.8273e-04 - acc: 1.0000 - val_loss: 4.6574e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 5.7868e-04 - acc: 1.0000\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.7389e-04 - acc: 1.0000 - val_loss: 4.1008e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 3.3724e-04 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 3.4018e-04 - acc: 1.0000 - val_loss: 1.5599e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 1.2937e-04 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.2817e-04 - acc: 1.0000 - val_loss: 6.0291e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "149/157 [===========================>..] - ETA: 0s - loss: 5.1015e-05 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.0113e-05 - acc: 1.0000 - val_loss: 3.0195e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 2.9003e-05 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.8946e-05 - acc: 1.0000 - val_loss: 2.0205e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 1.9991e-05 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.9797e-05 - acc: 1.0000 - val_loss: 1.4182e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 1.4517e-05 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.4517e-05 - acc: 1.0000 - val_loss: 1.1299e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "149/157 [===========================>..] - ETA: 0s - loss: 1.3286e-05 - acc: 1.0000\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.3010e-05 - acc: 1.0000 - val_loss: 9.8858e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 1.1882e-05 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1872e-05 - acc: 1.0000 - val_loss: 1.3522e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 4.3221e-04 - acc: 0.9998\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 4.3540e-04 - acc: 0.9998 - val_loss: 1.0719e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 6.5727e-05 - acc: 1.0000\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 6.5727e-05 - acc: 1.0000 - val_loss: 3.2137e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 1.0847e-04 - acc: 1.0000\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.0727e-04 - acc: 1.0000 - val_loss: 4.1498e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 3.7489e-05 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 3.6745e-05 - acc: 1.0000 - val_loss: 2.3165e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 34/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 2.2475e-05 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.2098e-05 - acc: 1.0000 - val_loss: 1.5167e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 35/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 1.5281e-05 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.5255e-05 - acc: 1.0000 - val_loss: 1.0713e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 36/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 1.1364e-05 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1297e-05 - acc: 1.0000 - val_loss: 8.2420e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 37/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 8.8998e-06 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 8.9066e-06 - acc: 1.0000 - val_loss: 6.5389e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 38/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 7.2272e-06 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 7.2137e-06 - acc: 1.0000 - val_loss: 5.3894e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 39/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 5.8526e-06 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.9974e-06 - acc: 1.0000 - val_loss: 4.5518e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 40/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 4.9504e-06 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.1108e-06 - acc: 1.0000 - val_loss: 3.9404e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 41/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 4.4271e-06 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 4.3978e-06 - acc: 1.0000 - val_loss: 3.4296e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 42/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 3.8630e-06 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 3.8297e-06 - acc: 1.0000 - val_loss: 3.0187e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 43/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 3.3471e-06 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 3.3469e-06 - acc: 1.0000 - val_loss: 2.6893e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 44/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 2.9812e-06 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.9362e-06 - acc: 1.0000 - val_loss: 2.4173e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 45/150\n",
      "150/157 [===========================>..] - ETA: 0s - loss: 2.6422e-06 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.6122e-06 - acc: 1.0000 - val_loss: 2.2185e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 46/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 2.3816e-06 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.3554e-06 - acc: 1.0000 - val_loss: 2.0222e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 47/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 2.1423e-06 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.1327e-06 - acc: 1.0000 - val_loss: 1.8910e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 48/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 1.9579e-06 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.9527e-06 - acc: 1.0000 - val_loss: 1.7459e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 49/150\n",
      "150/157 [===========================>..] - ETA: 0s - loss: 1.8103e-06 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.7809e-06 - acc: 1.0000 - val_loss: 1.6357e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 50/150\n",
      "150/157 [===========================>..] - ETA: 0s - loss: 1.5937e-06 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.6372e-06 - acc: 1.0000 - val_loss: 1.5013e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 51/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 1.5046e-06 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.5046e-06 - acc: 1.0000 - val_loss: 1.4078e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 52/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 1.3817e-06 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.4094e-06 - acc: 1.0000 - val_loss: 1.3541e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 53/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 1.3558e-06 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.3558e-06 - acc: 1.0000 - val_loss: 1.2969e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 54/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 1.3161e-06 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.2997e-06 - acc: 1.0000 - val_loss: 1.2430e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 55/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 1.2605e-06 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.2482e-06 - acc: 1.0000 - val_loss: 1.2038e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 56/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 1.2133e-06 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.2011e-06 - acc: 1.0000 - val_loss: 1.1548e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 57/150\n",
      "150/157 [===========================>..] - ETA: 0s - loss: 1.1665e-06 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1540e-06 - acc: 1.0000 - val_loss: 1.1257e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 58/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 1.1327e-06 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1129e-06 - acc: 1.0000 - val_loss: 1.0746e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 59/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 1.0721e-06 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.0665e-06 - acc: 1.0000 - val_loss: 1.0339e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 60/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 1.0248e-06 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.0248e-06 - acc: 1.0000 - val_loss: 9.9689e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 61/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 9.8895e-07 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 9.8794e-07 - acc: 1.0000 - val_loss: 9.5965e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 62/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 9.5122e-07 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 9.4859e-07 - acc: 1.0000 - val_loss: 9.1814e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 63/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 9.0484e-07 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 9.1209e-07 - acc: 1.0000 - val_loss: 8.8496e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 64/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 8.7894e-07 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 8.7517e-07 - acc: 1.0000 - val_loss: 8.5650e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 65/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 8.4564e-07 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 8.4564e-07 - acc: 1.0000 - val_loss: 8.5671e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 66/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 8.0090e-07 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 8.2393e-07 - acc: 1.0000 - val_loss: 8.2825e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 67/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 7.9210e-07 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 7.9210e-07 - acc: 1.0000 - val_loss: 7.8352e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 68/150\n",
      "150/157 [===========================>..] - ETA: 0s - loss: 7.5014e-07 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 7.6617e-07 - acc: 1.0000 - val_loss: 7.6126e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 69/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 7.4483e-07 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 7.4796e-07 - acc: 1.0000 - val_loss: 7.6918e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 70/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 7.2415e-07 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 7.1868e-07 - acc: 1.0000 - val_loss: 7.1054e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 71/150\n",
      "149/157 [===========================>..] - ETA: 0s - loss: 7.2095e-07 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 7.0761e-07 - acc: 1.0000 - val_loss: 7.0754e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 72/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 6.7795e-07 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 6.7466e-07 - acc: 1.0000 - val_loss: 6.5725e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 73/150\n",
      "150/157 [===========================>..] - ETA: 0s - loss: 6.2773e-07 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 6.5018e-07 - acc: 1.0000 - val_loss: 6.2558e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 74/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 6.4194e-07 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 6.4199e-07 - acc: 1.0000 - val_loss: 6.2022e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 75/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 5.6903e-07 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.9716e-07 - acc: 1.0000 - val_loss: 6.0760e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 76/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.7863e-07 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.8228e-07 - acc: 1.0000 - val_loss: 6.1530e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 77/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.5896e-07 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.5857e-07 - acc: 1.0000 - val_loss: 5.5281e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 78/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 5.2514e-07 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.2488e-07 - acc: 1.0000 - val_loss: 5.1300e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 79/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 5.3819e-07 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 5.3538e-07 - acc: 1.0000 - val_loss: 5.2713e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 80/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 4.7540e-07 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 4.7795e-07 - acc: 1.0000 - val_loss: 5.5880e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 81/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 4.5799e-07 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 4.5767e-07 - acc: 1.0000 - val_loss: 4.5308e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 82/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 4.3814e-07 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 4.3619e-07 - acc: 1.0000 - val_loss: 4.7705e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 83/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 4.1723e-07 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 4.1074e-07 - acc: 1.0000 - val_loss: 4.2740e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 84/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 3.8498e-07 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 3.8267e-07 - acc: 1.0000 - val_loss: 3.5763e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 85/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 3.5465e-07 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 3.5465e-07 - acc: 1.0000 - val_loss: 3.5656e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 86/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 3.3965e-07 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 3.3965e-07 - acc: 1.0000 - val_loss: 3.2574e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 87/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 3.2782e-07 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 3.2889e-07 - acc: 1.0000 - val_loss: 2.8529e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 88/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 2.9365e-07 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.9480e-07 - acc: 1.0000 - val_loss: 2.6474e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 89/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 2.7898e-07 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.7701e-07 - acc: 1.0000 - val_loss: 2.7758e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 90/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 2.6868e-07 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.6939e-07 - acc: 1.0000 - val_loss: 2.4227e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 91/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 2.4609e-07 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.4513e-07 - acc: 1.0000 - val_loss: 2.2237e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 92/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 2.6462e-07 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.6301e-07 - acc: 1.0000 - val_loss: 2.0974e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 93/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 2.2141e-07 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.1963e-07 - acc: 1.0000 - val_loss: 1.8620e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 94/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 2.0369e-07 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.0109e-07 - acc: 1.0000 - val_loss: 1.9305e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 95/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 1.9422e-07 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.9299e-07 - acc: 1.0000 - val_loss: 1.6223e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 96/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 1.8217e-07 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 1.8133e-07 - acc: 1.0000 - val_loss: 1.4446e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 97/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 1.6710e-07 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.6659e-07 - acc: 1.0000 - val_loss: 1.4425e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 98/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 1.5566e-07 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.5566e-07 - acc: 1.0000 - val_loss: 1.2135e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 99/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 1.5237e-07 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.5237e-07 - acc: 1.0000 - val_loss: 1.1600e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 100/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 1.4341e-07 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.4466e-07 - acc: 1.0000 - val_loss: 1.2477e-07 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 101/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 1.3053e-07 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.2980e-07 - acc: 1.0000 - val_loss: 9.5881e-08 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 102/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 1.1845e-07 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.1988e-07 - acc: 1.0000 - val_loss: 9.0745e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 103/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 1.1432e-07 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.1502e-07 - acc: 1.0000 - val_loss: 8.8604e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 104/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 1.0828e-07 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.1142e-07 - acc: 1.0000 - val_loss: 8.2398e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 105/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 1.0722e-07 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.0740e-07 - acc: 1.0000 - val_loss: 7.6405e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 106/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 1.0133e-07 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0059e-07 - acc: 1.0000 - val_loss: 8.4752e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 107/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 9.8854e-08 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 9.9686e-08 - acc: 1.0000 - val_loss: 7.4265e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 108/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 9.2523e-08 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 9.2258e-08 - acc: 1.0000 - val_loss: 6.8058e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 109/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 8.8046e-08 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 8.7877e-08 - acc: 1.0000 - val_loss: 6.4420e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 110/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 8.3295e-08 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 8.5306e-08 - acc: 1.0000 - val_loss: 6.2494e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 111/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 8.0782e-08 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 8.0782e-08 - acc: 1.0000 - val_loss: 5.7999e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 112/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 7.3040e-08 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 7.3687e-08 - acc: 1.0000 - val_loss: 5.5217e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 113/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 7.0132e-08 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 6.9902e-08 - acc: 1.0000 - val_loss: 5.5645e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 114/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 6.5241e-08 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 6.6688e-08 - acc: 1.0000 - val_loss: 5.1365e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 115/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 6.3548e-08 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 6.3569e-08 - acc: 1.0000 - val_loss: 4.7298e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 116/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 6.1335e-08 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 6.0926e-08 - acc: 1.0000 - val_loss: 4.6870e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 117/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 5.7831e-08 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 5.7831e-08 - acc: 1.0000 - val_loss: 5.4147e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 118/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.3236e-08 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 5.2926e-08 - acc: 1.0000 - val_loss: 4.2804e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 119/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 5.5278e-08 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 5.5545e-08 - acc: 1.0000 - val_loss: 4.1520e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 120/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 4.6651e-08 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 4.6593e-08 - acc: 1.0000 - val_loss: 3.8096e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 121/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 4.3629e-08 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 4.3784e-08 - acc: 1.0000 - val_loss: 3.3815e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 122/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 4.1291e-08 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 4.1427e-08 - acc: 1.0000 - val_loss: 3.0177e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 123/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 3.9512e-08 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 3.9546e-08 - acc: 1.0000 - val_loss: 3.6811e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 124/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 3.3546e-08 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 3.3546e-08 - acc: 1.0000 - val_loss: 2.6753e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 125/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 3.1283e-08 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 3.1261e-08 - acc: 1.0000 - val_loss: 2.5468e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 126/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 2.9149e-08 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 2.8832e-08 - acc: 1.0000 - val_loss: 2.2686e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 127/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 2.8488e-08 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 2.8380e-08 - acc: 1.0000 - val_loss: 2.5896e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 128/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 2.4594e-08 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.4594e-08 - acc: 1.0000 - val_loss: 1.8406e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 129/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 2.2037e-08 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.2213e-08 - acc: 1.0000 - val_loss: 1.7550e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 130/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 3.9320e-08 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 3.9284e-08 - acc: 1.0000 - val_loss: 3.2103e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 131/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 2.3087e-08 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.3070e-08 - acc: 1.0000 - val_loss: 1.7764e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 132/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 1.7146e-08 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.7118e-08 - acc: 1.0000 - val_loss: 1.4125e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 133/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 1.5748e-08 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 1.5714e-08 - acc: 1.0000 - val_loss: 1.3055e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 134/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 1.4079e-08 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 1.3999e-08 - acc: 1.0000 - val_loss: 1.1343e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 135/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 1.2895e-08 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.2880e-08 - acc: 1.0000 - val_loss: 1.0273e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 136/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 1.1974e-08 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 1.2214e-08 - acc: 1.0000 - val_loss: 1.5623e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 137/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 1.1078e-08 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.1071e-08 - acc: 1.0000 - val_loss: 7.9187e-09 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 138/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 9.4471e-09 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 9.4044e-09 - acc: 1.0000 - val_loss: 7.7047e-09 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 139/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 8.3574e-09 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 8.6187e-09 - acc: 1.0000 - val_loss: 6.2066e-09 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 140/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9756\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.1830 - acc: 0.9760 - val_loss: 1.0701e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 141/150\n",
      "153/157 [============================>.] - ETA: 0s - loss: 8.8414e-07 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 8.6485e-07 - acc: 1.0000 - val_loss: 1.0273e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 142/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 7.8945e-07 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 7.8708e-07 - acc: 1.0000 - val_loss: 1.0273e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 143/150\n",
      "154/157 [============================>.] - ETA: 0s - loss: 7.3452e-07 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 7.2353e-07 - acc: 1.0000 - val_loss: 1.0487e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 144/150\n",
      "152/157 [============================>.] - ETA: 0s - loss: 6.8705e-07 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 6.6771e-07 - acc: 1.0000 - val_loss: 1.0487e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 145/150\n",
      "156/157 [============================>.] - ETA: 0s - loss: 6.1649e-07 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 6.1464e-07 - acc: 1.0000 - val_loss: 1.0701e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 146/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 5.6873e-07 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 5.6873e-07 - acc: 1.0000 - val_loss: 1.1129e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 147/150\n",
      "150/157 [===========================>..] - ETA: 0s - loss: 5.4755e-07 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 5.2572e-07 - acc: 1.0000 - val_loss: 1.1129e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 148/150\n",
      "157/157 [==============================] - ETA: 0s - loss: 4.8593e-07 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 4.8593e-07 - acc: 1.0000 - val_loss: 1.1343e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 149/150\n",
      "151/157 [===========================>..] - ETA: 0s - loss: 4.6869e-07 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 4.5534e-07 - acc: 1.0000 - val_loss: 1.1771e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 150/150\n",
      "155/157 [============================>.] - ETA: 0s - loss: 4.2499e-07 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 4.2100e-07 - acc: 1.0000 - val_loss: 1.2199e-08 - val_acc: 1.0000 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=150,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model2.keras', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3745d7-0b46-412a-a7a0-fcf477e4600e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "048425ab-ee78-4472-8e6b-0e45541d7141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[427,   0],\n",
       "        [  0, 130]],\n",
       "\n",
       "       [[424,   0],\n",
       "        [  0, 133]],\n",
       "\n",
       "       [[400,   0],\n",
       "        [  0, 157]],\n",
       "\n",
       "       [[420,   0],\n",
       "        [  0, 137]]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('models/model2.keras')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca101996-cb48-49d8-a7b1-16e0a4dd1ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "actions = ['egg clap', 'wrist clap', 'fist clap', 'edge clap']\n",
    "seq_length = 20\n",
    "\n",
    "model = load_model('models/model2.keras')\n",
    "\n",
    "# MediaPipe hands model\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.3,\n",
    "    min_tracking_confidence=0.3)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "win_w, win_h = cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "left_hand_seq = []  \n",
    "right_hand_seq = []\n",
    "action_seq = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    img0 = img.copy()\n",
    "\n",
    "    img = cv2.flip(img, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "        for res in result.multi_hand_landmarks:\n",
    "            joint = np.zeros((21, 4))\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "            v = v2 - v1 # [20, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            wrist_x = res.landmark[0].x * img.shape[1]  \n",
    "            if wrist_x < img.shape[1] / 2:\n",
    "                left_hand_position = wrist_x\n",
    "                hand_side = \"Left\"\n",
    "            else:\n",
    "                right_hand_position = wrist_x\n",
    "                hand_side = \"Right\"\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle])\n",
    "\n",
    "            if wrist_x < img.shape[1] / 2:  \n",
    "                left_hand_seq.append(d)  \n",
    "            else:\n",
    "                right_hand_seq.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            if len(left_hand_seq) < seq_length or len(right_hand_seq) < seq_length:\n",
    "                continue\n",
    "\n",
    "            input_data_left = np.expand_dims(np.array(left_hand_seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "            input_data_right = np.expand_dims(np.array(right_hand_seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "\n",
    "            y_pred_left = model.predict(input_data_left).squeeze()\n",
    "            y_pred_right = model.predict(input_data_right).squeeze()\n",
    "\n",
    "            i_pred_left = int(np.argmax(y_pred_left))\n",
    "            i_pred_right = int(np.argmax(y_pred_right))\n",
    "\n",
    "            conf_left = y_pred_left[i_pred_left]\n",
    "            conf_right = y_pred_right[i_pred_right]\n",
    "\n",
    "            if conf_left < 0.8 or conf_right < 0.8:\n",
    "                continue\n",
    "\n",
    "            action_left = actions[i_pred_left]\n",
    "            action_right = actions[i_pred_right]\n",
    "            \n",
    "            if right_hand_position - left_hand_position < 200:\n",
    "                action = \"actioning..\"\n",
    "                if action_left == action_right:\n",
    "                    action = action_left\n",
    "            else:\n",
    "                action = \"...\"\n",
    "                         \n",
    "            cv2.putText(img, f'{action.upper()}', \n",
    "                        org=(int(win_w/2 - len(action.upper())*6), int(win_h/10)),  \n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0160a-5237-4d83-990d-ee02768c0136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
